services:
  caddy:
    image: caddy:2-alpine
    container_name: mdplanner-caddy
    ports:
      - "8080:8080"
      - "8443:8443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
    depends_on:
      - mdplanner
      - ollama
      - searxng
      - chatterbox
    restart: unless-stopped
    networks:
      - ai-net

  mdplanner:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: mdplanner
    volumes:
      - mdplanner-data:/data
      - mdplanner-backups:/backups
    # Secrets in .env next to this file:
    #   MDPLANNER_WEBDAV_USER=obsidian
    #   MDPLANNER_WEBDAV_PASS=changeme
    #   MDPLANNER_MCP_TOKEN=secret
    #   MDPLANNER_SECRET_KEY=<64-char hex>   # run: mdplanner keygen-secret
    #   MDPLANNER_BACKUP_PUBLIC_KEY=<PEM>    # run: mdplanner keygen  (public key only)
    environment:
      - MDPLANNER_CACHE=1
      - MDPLANNER_WEBDAV=1
      - MDPLANNER_WEBDAV_USER=${MDPLANNER_WEBDAV_USER}
      - MDPLANNER_WEBDAV_PASS=${MDPLANNER_WEBDAV_PASS}
      - MDPLANNER_MCP_TOKEN=${MDPLANNER_MCP_TOKEN:-}
      - MDPLANNER_READ_ONLY=${MDPLANNER_READ_ONLY:-}
      # Encryption key for integration secrets (e.g. Cloudflare API token stored in project.md).
      # Generate with: mdplanner keygen-secret
      # Set to a 32-byte hex string (64 hex chars). Leave empty to store tokens in plaintext.
      - MDPLANNER_SECRET_KEY=${MDPLANNER_SECRET_KEY:-}
      # Backup: output directory for scheduled exports. Mount a volume to persist outside container.
      - MDPLANNER_BACKUP_DIR=${MDPLANNER_BACKUP_DIR:-}
      # Backup schedule interval. Accepted values: daily, weekly. Leave empty to disable.
      - MDPLANNER_BACKUP_INTERVAL=${MDPLANNER_BACKUP_INTERVAL:-}
      # RSA-OAEP-4096 public key (PEM) for encrypted backups.
      # Generate keypair with: mdplanner keygen
      # Store only the PUBLIC key here. Private key stays with you — never in this file.
      # - MDPLANNER_BACKUP_PUBLIC_KEY=${MDPLANNER_BACKUP_PUBLIC_KEY:-}
    restart: unless-stopped
    networks:
      - ai-net

  ollama:
    image: ollama/ollama:0.16.2
    container_name: ollama
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=*
    restart: unless-stopped
    networks:
      - ai-net
    # ── GPU support (NVIDIA) ───────────────────────────────────────────────────
    # Linux + NVIDIA GPU: requires NVIDIA Container Toolkit
    #   https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
    # macOS / CPU-only: remove or comment out the entire deploy block below
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  chatterbox:
    build:
      context: ./chatterbox
    container_name: chatterbox
    volumes:
      # Voice reference WAV files — add your .wav files here
      - ./chatterbox/references:/app/references:ro
      # Cache downloaded HuggingFace models across restarts
      - huggingface-cache:/root/.cache/huggingface
    restart: unless-stopped
    networks:
      - ai-net
    # ── GPU support (NVIDIA) ───────────────────────────────────────────────────
    # macOS / CPU-only: remove or comment out the entire deploy block below
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    volumes:
      - ./searxng/settings.yml:/etc/searxng/settings.yml:ro
      - searxng-data:/var/cache/searxng
    restart: unless-stopped
    networks:
      - ai-net

networks:
  ai-net:
    driver: bridge

volumes:
  mdplanner-data:
  mdplanner-backups:
  ollama-data:
  huggingface-cache:
  searxng-data:
